{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long short term memory\n",
    "\n",
    "We previously explored RNNs, neural networks that are able to propagate some hidden state through a rolled out version of itself. A major problem with RNNs is exploding or vanishing gradients. Gradient clipping solves the exploding gradient problem, but the vanishing gradient problem is harder to solve. LSTMs propose a different architecture which benefits from a hidden state like RNNs, but mitigates the vanishing gradient problem. Another issue RNNs have is that the hidden state often forgets information from a while ago in the sequence and is more biased towards more recent tokens. LSTMs also address this issue with their gated structure. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.nn.utils.rnn import PackedSequence\n",
    "import torch.nn.functional\n",
    "from torch.utils.data import random_split\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM model defintion\n",
    "The goal here is to build a substitute for the torch.nn.rnn.lstm module. This should be able to handle packed sequences and batched data the same way the source code for that module does. For now, does not need to have multiple layers or be bidirectional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm(nn.Module): \n",
    "    def __init__(self, input_size, hidden_dim, output_dim=1) -> None:\n",
    "        super().__init__()\n",
    "        self.input_dim = input_size\n",
    "        self.hidden_dim  = hidden_dim\n",
    "        \n",
    "        self.forget_gate = nn.Sequential(\n",
    "            nn.Linear(input_size+hidden_dim, hidden_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.input_gate = nn.Sequential(\n",
    "            nn.Linear(input_size+hidden_dim, hidden_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.input_node = nn.Sequential(\n",
    "            nn.Linear(input_size+hidden_dim, hidden_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.output_gate = nn.Sequential(\n",
    "            nn.Linear(input_size+hidden_dim, hidden_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        # this output layer can be fancier if needed by the use case\n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, h_in=None, c_in=None):\n",
    "\n",
    "        if isinstance(x, PackedSequence):\n",
    "            input, batch_sizes, sorted_indices, unsorted_indices = x\n",
    "            max_batch_size = batch_sizes[0]\n",
    "            if h_in is None: \n",
    "                h_in = self.init_h(max_batch_size, x)\n",
    "                c_in = self.init_h(max_batch_size, x)\n",
    "        \n",
    "            data_offset = 0\n",
    "            outputs = []\n",
    "            for batch_size in batch_sizes:\n",
    "                current_input = input[data_offset:data_offset + batch_size]\n",
    "                data_offset += batch_size\n",
    "                current_input = current_input.unsqueeze(0)\n",
    "                if batch_size < max_batch_size: \n",
    "                    h_in[:,batch_size:,:] = 0\n",
    "                    c_in[:,batch_size:,:] = 0\n",
    "                    pad_size = max_batch_size - batch_size\n",
    "                    # Create a tensor of zeros with the padding size\n",
    "                    padding = torch.zeros(1, pad_size, self.hidden_dim, device=current_input.device)\n",
    "                    # Concatenate the padding to the current input\n",
    "                    current_input = torch.cat([current_input, padding], dim=1)\n",
    "                \n",
    "                combined = torch.cat([current_input, h_in], dim=2)\n",
    "                \n",
    "                i_gate_output = self.input_gate(combined)\n",
    "                i_node_output = self.input_node(combined)\n",
    "                o_gate_output = self.output_gate(combined)\n",
    "                f_gate_output = self.forget_gate(combined)\n",
    "\n",
    "                c_out = (f_gate_output * c_in) + (i_node_output * i_gate_output)\n",
    "\n",
    "                h_out = self.tanh(c_out) * o_gate_output\n",
    "                out = self.output_layer(h_out)\n",
    "                h_in = h_out\n",
    "                c_in = c_out\n",
    "                outputs.append(out)\n",
    "\n",
    "                # Handle decreasing batch siz\n",
    "            output_packed = PackedSequence(outputs, batch_sizes, sorted_indices, unsorted_indices)\n",
    "            return output_packed, (h_out, c_out)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            for t in range(x.size(1)):\n",
    "                input = x[:,t,:]\n",
    "                combined = torch.cat([x, h_in], dim=2)\n",
    "                        \n",
    "                i_gate_output = self.input_gate(combined)\n",
    "                i_node_output = self.input_node(combined)\n",
    "                o_gate_output = self.output_gate(combined)\n",
    "                f_gate_output = self.forget_gate(combined)\n",
    "\n",
    "                c_out = (f_gate_output * c_in) + (i_node_output * i_gate_output)\n",
    "                h_out = self.tanh(c_out) * o_gate_output\n",
    "                out = self.output_layer(h_out)\n",
    "                h_in = h_out \n",
    "                c_in = c_out\n",
    "            \n",
    "        return out, (h_out, c_out)\n",
    "    \n",
    "    \n",
    "    def init_h(self, batch_size, sequence_length):\n",
    "        #zero initialization \n",
    "        #alternatives include but not limited to Xavier/Kaiminh initialization\n",
    "        return torch.zeros(batch_size, sequence_length, self.hidden_dim, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "class newsLSTM(nn.Module): \n",
    "    def __init__(self, vocab_size, embed_size, hidden_size) -> None:\n",
    "        super(newsLSTM, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        self.hidden_size = hidden_size \n",
    "        self.lstm = nn.LSTM(embed_size, \n",
    "                           hidden_size,\n",
    "                           batch_first=True)\n",
    "        \n",
    "        self.hidden2label = nn.Linear(hidden_size, 4)\n",
    "        self.dropoutLayer = nn.Dropout(p=0.5)\n",
    "\n",
    "\n",
    "    def forward(self, x, x_len):\n",
    "        embedded = self.encoder(x)\n",
    "        x_packed = nn.utils.rnn.pack_padded_sequence(embedded, x_len, batch_first=True, enforce_sorted=False)\n",
    "        output, (h_t, c_t) = self.lstm(x_packed)  # Pass the initial hidden state 'h' to the RNN   \n",
    "        # hidden = self.dropout(torch.cat((h_t[-2,:,:], h_t[-1,:,:]), dim=1))     \n",
    "        hidden = self.dropoutLayer(h_t.squeeze())\n",
    "        \n",
    "        # Linear layer and softmax\n",
    "        label_space = self.hidden2label(hidden)\n",
    "        \n",
    "        return label_space\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat the exact same news classification task performed by in the bidirectionalRNN subdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = AG_NEWS(split='train')\n",
    "\n",
    "# Convert to list to enable random splitting\n",
    "train_dataset = list(train_iter)\n",
    "\n",
    "#80-20 train-val split \n",
    "train_size = int(len(train_dataset) * 0.8)  \n",
    "val_size = len(train_dataset) - train_size  \n",
    "train_data, val_data = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "VOCAB_SIZE = 5000\n",
    "\n",
    "# Build vocab based on the train_data\n",
    "train_data_iter = (text for _, text in train_data)\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_data_iter), specials=[\"<unk>\"], max_tokens=VOCAB_SIZE)\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " 'Audit of Venezuelan vote backs Chavez An audit of Venezuela #39;s referendum results has confirmed that President Hugo Chavez won the poll fairly and found no evidence to support the opposition #39;s claims of widespread vote-rigging, international observers said ')"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2199, 1699, 4681, 0]"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['word', 'probably', 'unknown', 'gibberish'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['muqtada']"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.lookup_tokens([4999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "    \n",
    "    # Sort the batch in the descending order\n",
    "    batch.sort(key=lambda x: len(x[1]), reverse=True)\n",
    "    \n",
    "    for _label, _text in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        lengths.append(processed_text.size(0))\n",
    "        \n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    lengths = torch.tensor(lengths, dtype=torch.int64)\n",
    "    \n",
    "    # Pad sequences\n",
    "    text_list = pad_sequence(text_list, batch_first=True)\n",
    "    \n",
    "    return label_list.to(device), text_list.to(device), lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size = 8, shuffle = True, collate_fn = collate_batch)\n",
    "val_loader = DataLoader(val_data, batch_size = 8, shuffle = False, collate_fn = collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "\n",
    "# Inspect the shape of the input data\n",
    "input_data = batch[1]  # Assuming the input data is the first element of the batch\n",
    "input_shape = input_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 70])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =  torch.ones(5, 50)\n",
    "a =  torch.ones(5, 50)\n",
    "a =  torch.ones(5, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Softmax(dim=1)\n",
    "input = torch.randn(2, 3)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3639,  0.2005, -0.1079],\n",
       "        [ 2.1012, -0.9496, -2.1717]])"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4044, 0.3434, 0.2523],\n",
       "        [0.9423, 0.0446, 0.0131]])"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 0, 1, 1, 2, 3, 1], device='cuda:0')\n",
      "torch.Size([8, 70])\n"
     ]
    }
   ],
   "source": [
    "print(batch[0])\n",
    "print(batch[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10\n",
    "DROPOUT = 0.5\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "EMBEDDING_DIM = 128\n",
    "BIDIRECTIONAL = True\n",
    "HIDDEN_DIM = 128\n",
    "NUM_LAYERS = 2\n",
    "OUTPUT_DIM = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = newsLSTM(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM)\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, loss_function, optim, epochs, device):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        losses = [] #group losses for loss visualization \n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "        print(\"Epoch %d / %d\" % (epoch+1, epochs))\n",
    "        print(\"-\"*10)\n",
    "    \n",
    "        for i, batch_data in enumerate(train_loader):\n",
    "            \n",
    "            model.train()\n",
    "            (y, x, x_size) = batch_data\n",
    "            y_pred = model(x, x_size.cpu())\n",
    "            #print(f\"y_pred: {y_pred}, y_target: {y}\")\n",
    "            loss = loss_function(y_pred, y)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            losses.append(loss)\n",
    "            \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        print(\"Epoch: {}, train loss: {:.4f}\".format(epoch+1, running_loss/len(losses)))\n",
    "        with torch.no_grad():\n",
    "            for i, batch_data in enumerate(val_loader):\n",
    "                (y, x, x_size) = batch_data\n",
    "                y, x, x_size = y.to(device), x.to(device), x_size.to(device)\n",
    "                \n",
    "                y_pred = model(x, x_size.cpu())\n",
    "                loss = loss_function(y_pred, y)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        print(\"Epoch: {}, validation loss: {:.4f}\".format(epoch+1, val_loss/len(val_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[346], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(model, train_loader, val_loader, torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49mcross_entropy, optimizer, NUM_EPOCHS, DEVICE)\n",
      "Cell \u001b[0;32mIn[345], line 21\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, loss_function, optim, epochs, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     19\u001b[0m     optim\u001b[39m.\u001b[39mstep()\n\u001b[0;32m---> 21\u001b[0m     running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m     22\u001b[0m     losses\u001b[39m.\u001b[39mappend(loss)\n\u001b[1;32m     24\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, train_loader, val_loader, torch.nn.functional.cross_entropy, optimizer, NUM_EPOCHS, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes: \n",
    "\n",
    "Something about the handling of decreasing batch sizes and packed sequences makes our lstm from scratch inefficient at learning when compared to the native torch version. However, working through the implementation and the bugs that came with it helped me better understand the internals of the lstm. What's especially impressive is that using a single layered unidirectional LSTM is much more effective for learning on this task than a 2 layered bidirectional RNN (see `RecurrentNetworks/bidirectionalRNN`)\n",
    "\n",
    "Below, we still make use of our hand crafted LSTM for a non batched, non-packed use case where it should not suffer from its inefficiencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_scratch_model(model, data_loader, loss_function, optim, epochs, device, scheduler, start_decay):\n",
    "    \n",
    "    losses = [] #group losses for loss visualization \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0 \n",
    "        print(\"Epoch %d / %d\" % (epoch+1, epochs))\n",
    "        print(\"-\"*10)\n",
    "        if (epoch > start_decay): \n",
    "            scheduler.step()\n",
    "        \n",
    "\n",
    "        for i, (x, y) in enumerate(data_loader):\n",
    "            h_s = model.init_h(x.shape[0], x.shape[1]).to(device) \n",
    "            c_s = model.init_h(x.shape[0], x.shape[1]).to(device) \n",
    "            \n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            y_pred, (h_out, c_out) = model(x, h_s, c_s)\n",
    "            y_pred = y_pred[:, -1, :]\n",
    "            \n",
    "            h_s = h_out\n",
    "            c_s = c_out\n",
    "            \n",
    "            loss = loss_function(y_pred, y) \n",
    "            running_loss+=loss.item()\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            loss.backward(retain_graph=True) #backprop \n",
    "            optim.step() #update weights\n",
    "  \n",
    "        losses.append((running_loss / i))\n",
    "        print(\"Step: {}/{}, current Epoch loss: {:.4f}\".format(i, len(data_loader), (running_loss / i)))\n",
    "        \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(stock, sequence_length):\n",
    "    # Convert pandas dataframe to numpy array\n",
    "    data_raw = stock.to_numpy()\n",
    "\n",
    "    data = []\n",
    "\n",
    "    # Loop over the stock data to generate sequences of 'sequence_length' consecutive data points\n",
    "    # This is done because RNNs learn to predict data in a sequence from past sequence\n",
    "    for index in range(len(data_raw) - sequence_length):\n",
    "        data.append(data_raw[index: index + sequence_length])\n",
    "\n",
    "    data = np.array(data)\n",
    "    set_size = int(data.shape[0])\n",
    "\n",
    "    # Generate the train data\n",
    "    # x_train is all sequences excluding the last data point from each sequence\n",
    "    x = data[:,:-1,:]\n",
    "    # y_train is the last data point from each sequence\n",
    "    y = data[:,-1,:]\n",
    "    \n",
    "\n",
    "    # Return the train and test data\n",
    "    return [x, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_df = pd.read_csv('IBM.csv')\n",
    "ibm_df['Date'] = pd.to_datetime(ibm_df['Date'])\n",
    "ibm_df.set_index('Date',inplace=True)\n",
    "ibm_df = ibm_df[['Close']]\n",
    "\n",
    "# Get the number of rows in the DataFrame\n",
    "num_rows = ibm_df.shape[0]\n",
    "\n",
    "# Compute the split point\n",
    "split_point = int(num_rows*0.8)\n",
    "\n",
    "# Split the DataFrame\n",
    "train_df = ibm_df.iloc[:split_point]\n",
    "test_df = ibm_df.iloc[split_point:]\n",
    "\n",
    "x_train, y_train = load_data(train_df, 10) \n",
    "x_test, y_test = load_data(test_df, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Close\n",
      "Date             \n",
      "2006-01-03  82.06\n",
      "2006-01-04  81.95\n",
      "2006-01-05  82.50\n",
      "2006-01-06  84.95\n",
      "2006-01-09  83.73\n"
     ]
    }
   ],
   "source": [
    "print(train_df.head()) #to ensure no shuffling accidentally occurred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Close\n",
      "Date              \n",
      "2017-12-22  152.50\n",
      "2017-12-26  152.83\n",
      "2017-12-27  153.13\n",
      "2017-12-28  154.04\n",
      "2017-12-29  153.42\n"
     ]
    }
   ],
   "source": [
    "print(test_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train input data shape: (2406, 9, 1), target shape: (2406, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train input data shape: {}, target shape: {}\".format(x_train.shape, y_train.shape)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test input data shape: (594, 9, 1), target shape: (594, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test input data shape: {}, target shape: {}\".format(x_test.shape, y_test.shape)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(x_train).type(torch.Tensor)\n",
    "x_test = torch.from_numpy(x_test).type(torch.Tensor)\n",
    "y_train = torch.from_numpy(y_train).type(torch.Tensor)\n",
    "y_test = torch.from_numpy(y_test).type(torch.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torch.utils.data.TensorDataset(x_train,y_train)\n",
    "test_set = torch.utils.data.TensorDataset(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 1000\n",
    "BATCH_SIZE = 32 \n",
    "LEARNING_RATE = 3e-4\n",
    "INPUT_DIM = 1 \n",
    "OUTPUT_DIM = 1 \n",
    "HIDDEN_DIM = 32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, \n",
    "                                           batch_size=BATCH_SIZE, \n",
    "                                           shuffle=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, \n",
    "                                          batch_size=BATCH_SIZE, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm(INPUT_DIM, HIDDEN_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "DECAY_FACTOR = 0.1\n",
    "DECAY_EPOCHS = 20\n",
    "START_DECAY_EPOCH = 50\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=DECAY_EPOCHS, gamma=DECAY_FACTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 1000\n",
      "----------\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aryaman.pandya/ml_accel/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([6, 9, 1])\n",
      "Step: 75/76, current Epoch loss: 22763.2450\n",
      "Epoch 2 / 1000\n",
      "----------\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([6, 9, 1])\n",
      "Step: 75/76, current Epoch loss: 22576.3143\n",
      "Epoch 3 / 1000\n",
      "----------\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([6, 9, 1])\n",
      "Step: 75/76, current Epoch loss: 22307.0335\n",
      "Epoch 4 / 1000\n",
      "----------\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([6, 9, 1])\n",
      "Step: 75/76, current Epoch loss: 22121.7218\n",
      "Epoch 5 / 1000\n",
      "----------\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([6, 9, 1])\n",
      "Step: 75/76, current Epoch loss: 21756.3042\n",
      "Epoch 6 / 1000\n",
      "----------\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([6, 9, 1])\n",
      "Step: 75/76, current Epoch loss: 21288.3045\n",
      "Epoch 7 / 1000\n",
      "----------\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([6, 9, 1])\n",
      "Step: 75/76, current Epoch loss: 21007.6526\n",
      "Epoch 8 / 1000\n",
      "----------\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([6, 9, 1])\n",
      "Step: 75/76, current Epoch loss: 20769.6171\n",
      "Epoch 9 / 1000\n",
      "----------\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([6, 9, 1])\n",
      "Step: 75/76, current Epoch loss: 20545.0433\n",
      "Epoch 10 / 1000\n",
      "----------\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([6, 9, 1])\n",
      "Step: 75/76, current Epoch loss: 20329.8737\n",
      "Epoch 11 / 1000\n",
      "----------\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([6, 9, 1])\n",
      "Step: 75/76, current Epoch loss: 20086.0749\n",
      "Epoch 12 / 1000\n",
      "----------\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([6, 9, 1])\n",
      "Step: 75/76, current Epoch loss: 19877.7269\n",
      "Epoch 13 / 1000\n",
      "----------\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([6, 9, 1])\n",
      "Step: 75/76, current Epoch loss: 19680.2060\n",
      "Epoch 14 / 1000\n",
      "----------\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n",
      "x size: torch.Size([32, 9, 1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[362], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m losses \u001b[39m=\u001b[39m train_scratch_model(model\u001b[39m=\u001b[39;49mmodel, data_loader\u001b[39m=\u001b[39;49mtrain_loader, loss_function\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mMSELoss(size_average\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m), optim\u001b[39m=\u001b[39;49moptimizer, epochs\u001b[39m=\u001b[39;49mNUM_EPOCHS, device\u001b[39m=\u001b[39;49mdevice, scheduler\u001b[39m=\u001b[39;49mscheduler, \\\n\u001b[1;32m      2\u001b[0m     start_decay\u001b[39m=\u001b[39;49mSTART_DECAY_EPOCH)\n",
      "Cell \u001b[0;32mIn[347], line 20\u001b[0m, in \u001b[0;36mtrain_scratch_model\u001b[0;34m(model, data_loader, loss_function, optim, epochs, device, scheduler, start_decay)\u001b[0m\n\u001b[1;32m     17\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     18\u001b[0m y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 20\u001b[0m y_pred, (h_out, c_out) \u001b[39m=\u001b[39m model(x, h_s, c_s)\n\u001b[1;32m     21\u001b[0m y_pred \u001b[39m=\u001b[39m y_pred[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\n\u001b[1;32m     23\u001b[0m h_s \u001b[39m=\u001b[39m h_out\n",
      "File \u001b[0;32m~/ml_accel/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/ml_accel/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[325], line 85\u001b[0m, in \u001b[0;36mlstm.forward\u001b[0;34m(self, x, h_in, c_in)\u001b[0m\n\u001b[1;32m     83\u001b[0m c_out \u001b[39m=\u001b[39m (f_gate_output \u001b[39m*\u001b[39m c_in) \u001b[39m+\u001b[39m (i_node_output \u001b[39m*\u001b[39m i_gate_output)\n\u001b[1;32m     84\u001b[0m h_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtanh(c_out) \u001b[39m*\u001b[39m o_gate_output\n\u001b[0;32m---> 85\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_layer(h_out)\n\u001b[1;32m     86\u001b[0m h_in \u001b[39m=\u001b[39m h_out \n\u001b[1;32m     87\u001b[0m c_in \u001b[39m=\u001b[39m c_out\n",
      "File \u001b[0;32m~/ml_accel/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/ml_accel/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ml_accel/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = train_scratch_model(model=model, data_loader=train_loader, loss_function=torch.nn.MSELoss(size_average=True), optim=optimizer, epochs=NUM_EPOCHS, device=device, scheduler=scheduler, \\\n",
    "    start_decay=START_DECAY_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_accel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
