{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long short term memory\n",
    "\n",
    "We previously explored RNNs, neural networks that are able to propagate some hidden state through a rolled out version of itself. A major problem with RNNs is exploding or vanishing gradients. Gradient clipping solves the exploding gradient problem, but the vanishing gradient problem is harder to solve. LSTMs propose a different architecture which benefits from a hidden state like RNNs, but mitigates the vanishing gradient problem. Another issue RNNs have is that the hidden state often forgets information from a while ago in the sequence and is more biased towards more recent tokens. LSTMs also address this issue with their gated structure. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.nn.utils.rnn import PackedSequence\n",
    "import torch.nn.functional\n",
    "from torch.utils.data import random_split\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM model defintion\n",
    "The goal here is to build a substitute for the torch.nn.rnn.lstm module. This should be able to handle packed sequences and batched data the same way the source code for that module does. For now, does not need to have multiple layers or be bidirectional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module): \n",
    "\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, bias=True):\n",
    "        super(LSTMCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "\n",
    "        self.x2h = nn.Linear(input_size, 4 * hidden_size, bias=bias)\n",
    "        self.h2h = nn.Linear(hidden_size, 4 * hidden_size, bias=bias)\n",
    "        self.reset_parameters()\n",
    "\n",
    "\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        std = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for w in self.parameters():\n",
    "            w.data.uniform_(-std, std)\n",
    "    \n",
    "    def forward(self, x, hidden, cell_state):\n",
    "\n",
    "        #pdb.set_trace()\n",
    "        hx = hidden\n",
    "        \n",
    "        x = x.view(-1, x.size(1))\n",
    "        \n",
    "        gates = self.x2h(x) + self.h2h(hx)\n",
    "    \n",
    "        gates = gates.squeeze()\n",
    "        \n",
    "        i_gate, f_gate, c_gate, o_gate = gates.chunk(4, 1)\n",
    "        \n",
    "        in_gate = torch.sigmoid(i_gate)\n",
    "        forget_gate = torch.sigmoid(f_gate)\n",
    "        g_t = torch.tanh(c_gate)\n",
    "        cell_state_clone = cell_state.clone()\n",
    "        cell_gate = torch.mul(forget_gate, cell_state_clone) + torch.mul(in_gate, g_t)\n",
    "\n",
    "        out_gate = torch.sigmoid(o_gate)\n",
    "        \n",
    "\n",
    "        hm = out_gate * nn.functional.tanh(cell_gate)\n",
    "        return (hm, cell_gate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm(nn.Module): \n",
    "    def __init__(self, input_size, hidden_dim, num_layers, output_dim=1) -> None:\n",
    "        super().__init__()\n",
    "        self.input_dim = input_size\n",
    "        self.hidden_dim  = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.lstm_cell_list = nn.ModuleList()\n",
    "        for _ in range(self.num_layers): \n",
    "            self.lstm_cell_list.append(LSTMCell(self.input_dim, self.hidden_dim))\n",
    "        \n",
    "        self.fc = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "\n",
    "    def forward(self, x, h_in=None, c_in=None):\n",
    "\n",
    "        if isinstance(x, PackedSequence):\n",
    "            input, batch_sizes, sorted_indices, unsorted_indices = x\n",
    "            max_batch_size = batch_sizes[0]\n",
    "            if h_in is None: \n",
    "                h_in = self.init_h(max_batch_size, x)\n",
    "                c_in = self.init_h(max_batch_size, x)\n",
    "        \n",
    "            data_offset = 0\n",
    "            outputs = []\n",
    "            for batch_size in batch_sizes:\n",
    "                current_input = input[data_offset:data_offset + batch_size]\n",
    "                data_offset += batch_size\n",
    "                current_input = current_input.unsqueeze(0)\n",
    "                if batch_size < max_batch_size: \n",
    "                    h_in[:,batch_size:,:] = 0\n",
    "                    c_in[:,batch_size:,:] = 0\n",
    "                    pad_size = max_batch_size - batch_size\n",
    "                    # Create a tensor of zeros with the padding size\n",
    "                    padding = torch.zeros(1, pad_size, self.hidden_dim, device=current_input.device)\n",
    "                    # Concatenate the padding to the current input\n",
    "                    current_input = torch.cat([current_input, padding], dim=1)\n",
    "                \n",
    "                combined = torch.cat([current_input, h_in], dim=2)\n",
    "                \n",
    "                i_gate_output = self.input_gate(combined)\n",
    "                i_node_output = self.input_node(combined)\n",
    "                o_gate_output = self.output_gate(combined)\n",
    "                f_gate_output = self.forget_gate(combined)\n",
    "\n",
    "                c_out = (f_gate_output * c_in) + (i_node_output * i_gate_output)\n",
    "\n",
    "                h_out = self.tanh(c_out) * o_gate_output\n",
    "                out = self.output_layer(h_out)\n",
    "                h_in = h_out\n",
    "                c_in = c_out\n",
    "                outputs.append(out)\n",
    "\n",
    "                # Handle decreasing batch siz\n",
    "            output_packed = PackedSequence(outputs, batch_sizes, sorted_indices, unsorted_indices)\n",
    "            return output_packed, (h_out, c_out)\n",
    "        \n",
    "        else:\n",
    "            if h_in is None: \n",
    "                h_in = self.init_h(x.size(0)).to(x.device)\n",
    "                c_in = self.init_h(x.size(0)).to(x.device)\n",
    "            h_tmp = h_in.clone()\n",
    "            c_tmp = c_in.clone()\n",
    "            for t in range(x.size(1)):\n",
    "                print(t)\n",
    "                for layer in range(self.num_layers): \n",
    "                    input = x[:,t,:]\n",
    "                    if layer == 0: \n",
    "                        (h_out, c_out) = self.lstm_cell_list[layer](input, h_in[layer], c_in[layer])  # if first hidden layer, use input\n",
    "                    else: \n",
    "                        (h_out, c_out) = self.lstm_cell_list[layer](h_in[layer - 1], h_in[layer], c_in[layer])  # else, use previous hidden layer as input \n",
    "                    h_tmp[layer] = h_out\n",
    "                    c_tmp[layer] = c_out\n",
    "            \n",
    "        return h_out, c_out\n",
    "    \n",
    "    \n",
    "    def init_h(self, batch_size):\n",
    "        #zero initialization \n",
    "        #alternatives include but not limited to Xavier/Kaiminh initialization\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_dim, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm_simplified(nn.Module): \n",
    "    def __init__(self, input_size, hidden_dim, output_dim=1) -> None:\n",
    "        super().__init__()\n",
    "        self.input_dim = input_size\n",
    "        self.hidden_dim  = hidden_dim\n",
    "        \n",
    "        self.x_h = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_dim * 4),\n",
    "        )\n",
    "        self.h_x = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim * 4),\n",
    "        )\n",
    "\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        # this output layer can be fancier if needed by the use case\n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, h_in=None, c_in=None):\n",
    "\n",
    "        if isinstance(x, PackedSequence):\n",
    "            input, batch_sizes, sorted_indices, unsorted_indices = x\n",
    "            max_batch_size = batch_sizes[0]\n",
    "            if h_in is None: \n",
    "                h_in = self.init_h(max_batch_size, x)\n",
    "                c_in = self.init_h(max_batch_size, x)\n",
    "        \n",
    "            data_offset = 0\n",
    "            outputs = []\n",
    "            for batch_size in batch_sizes:\n",
    "                current_input = input[data_offset:data_offset + batch_size]\n",
    "                data_offset += batch_size\n",
    "                current_input = current_input.unsqueeze(0)\n",
    "                if batch_size < max_batch_size: \n",
    "                    h_in[:,batch_size:,:] = 0\n",
    "                    c_in[:,batch_size:,:] = 0\n",
    "                    pad_size = max_batch_size - batch_size\n",
    "                    # Create a tensor of zeros with the padding size\n",
    "                    padding = torch.zeros(1, pad_size, self.hidden_dim, device=current_input.device)\n",
    "                    # Concatenate the padding to the current input\n",
    "                    current_input = torch.cat([current_input, padding], dim=1)\n",
    "                \n",
    "                gates = self.x_h(current_input) +  self.h_x(h_in)\n",
    "                input_gate, forget_gate, input_node, output_gate = gates.chunk(4, 2)\n",
    "                i_gate_output = torch.sigmoid(input_gate)\n",
    "                i_node_output = torch.tanh(input_node)\n",
    "                o_gate_output = torch.sigmoid(output_gate)\n",
    "                f_gate_output = torch.sigmoid(forget_gate)\n",
    "                \n",
    "                c_out = (f_gate_output * c_in) + (i_node_output * i_gate_output)\n",
    "\n",
    "                h_out = self.tanh(c_out) * o_gate_output\n",
    "                out = self.output_layer(h_out)\n",
    "                h_in = h_out\n",
    "                c_in = c_out\n",
    "                outputs.append(out)\n",
    "\n",
    "                # Handle decreasing batch siz\n",
    "\n",
    "\n",
    "            output_packed = PackedSequence(outputs, batch_sizes, sorted_indices, unsorted_indices)\n",
    "            return output_packed, h_out, c_out\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            for t in range(x.size(1)):\n",
    "                input = x[:,t,:]\n",
    "                gates = self.x_h(input) +  self.h_x(h_in)\n",
    "                input_gate, forget_gate, input_node, output_gate = gates.chunk(4, 1)\n",
    "                i_gate_output = torch.sigmoid(input_gate)\n",
    "                i_node_output = torch.tanh(input_node)\n",
    "                o_gate_output = torch.sigmoid(output_gate)\n",
    "                f_gate_output = torch.sigmoid(forget_gate)\n",
    "                \n",
    "                c_out = (f_gate_output * c_in) + (i_node_output * i_gate_output)\n",
    "\n",
    "                h_out = self.tanh(c_out) * o_gate_output\n",
    "                out = self.output_layer(h_out)\n",
    "                h_in = h_out\n",
    "                c_in = c_out\n",
    "            \n",
    "        return out, (h_out, c_out)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def init_h(self, batch_size, sequence_length):\n",
    "        #zero initialization \n",
    "        #alternatives include but not limited to Xavier/Kaiminh initialization\n",
    "        return torch.zeros(batch_size, self.hidden_dim, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "class newsLSTM(nn.Module): \n",
    "    def __init__(self, vocab_size, embed_size, hidden_size) -> None:\n",
    "        super(newsLSTM, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        self.hidden_size = hidden_size \n",
    "        self.lstm = nn.LSTM(embed_size, \n",
    "                           hidden_size,\n",
    "                           batch_first=True)\n",
    "        \n",
    "        self.hidden2label = nn.Linear(hidden_size, 4)\n",
    "        self.dropoutLayer = nn.Dropout(p=0.5)\n",
    "\n",
    "\n",
    "    def forward(self, x, x_len):\n",
    "        embedded = self.encoder(x)\n",
    "        x_packed = nn.utils.rnn.pack_padded_sequence(embedded, x_len, batch_first=True, enforce_sorted=False)\n",
    "        output, (h_t, c_t) = self.lstm(x_packed)  # Pass the initial hidden state 'h' to the RNN   \n",
    "        # hidden = self.dropout(torch.cat((h_t[-2,:,:], h_t[-1,:,:]), dim=1))     \n",
    "        hidden = self.dropoutLayer(h_t.squeeze())\n",
    "        \n",
    "        # Linear layer and softmax\n",
    "        label_space = self.hidden2label(hidden)\n",
    "        \n",
    "        return label_space\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat the exact same news classification task performed by in the bidirectionalRNN subdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = AG_NEWS(split='train')\n",
    "\n",
    "# Convert to list to enable random splitting\n",
    "train_dataset = list(train_iter)\n",
    "\n",
    "#80-20 train-val split \n",
    "train_size = int(len(train_dataset) * 0.8)  \n",
    "val_size = len(train_dataset) - train_size  \n",
    "train_data, val_data = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "VOCAB_SIZE = 5000\n",
    "\n",
    "# Build vocab based on the train_data\n",
    "train_data_iter = (text for _, text in train_data)\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_data_iter), specials=[\"<unk>\"], max_tokens=VOCAB_SIZE)\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " \"Denver's Rodney White Suspended by NBA (AP) AP - Denver Nuggets forward Rodney White was suspended without pay for one game by the NBA on Thursday for pleading guilty to unlawful possession of a weapon.\")"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2088, 1612, 4962, 0]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['word', 'probably', 'unknown', 'gibberish'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7fc63de434f0>"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['underway']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.lookup_tokens([4999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "    \n",
    "    # Sort the batch in the descending order\n",
    "    batch.sort(key=lambda x: len(x[1]), reverse=True)\n",
    "    \n",
    "    for _label, _text in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        lengths.append(processed_text.size(0))\n",
    "        \n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    lengths = torch.tensor(lengths, dtype=torch.int64)\n",
    "    \n",
    "    # Pad sequences\n",
    "    text_list = pad_sequence(text_list, batch_first=True)\n",
    "    \n",
    "    return label_list.to(device), text_list.to(device), lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size = 8, shuffle = True, collate_fn = collate_batch)\n",
    "val_loader = DataLoader(val_data, batch_size = 8, shuffle = False, collate_fn = collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "\n",
    "# Inspect the shape of the input data\n",
    "input_data = batch[1]  # Assuming the input data is the first element of the batch\n",
    "input_shape = input_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 49])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =  torch.ones(5, 50)\n",
    "a =  torch.ones(5, 50)\n",
    "a =  torch.ones(5, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Softmax(dim=1)\n",
    "input = torch.randn(2, 3)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7087, -0.2223, -0.8642],\n",
       "        [-0.8228,  0.4882, -0.7226]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6244, 0.2461, 0.1295],\n",
       "        [0.1720, 0.6380, 0.1901]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 2, 0, 3, 1, 1, 1], device='cuda:0')\n",
      "torch.Size([8, 49])\n"
     ]
    }
   ],
   "source": [
    "print(batch[0])\n",
    "print(batch[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10\n",
    "DROPOUT = 0.5\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "EMBEDDING_DIM = 128\n",
    "BIDIRECTIONAL = True\n",
    "HIDDEN_DIM = 128\n",
    "NUM_LAYERS = 2\n",
    "OUTPUT_DIM = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = newsLSTM(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM)\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, loss_function, optim, epochs, device):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        losses = [] #group losses for loss visualization \n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "        print(\"Epoch %d / %d\" % (epoch+1, epochs))\n",
    "        print(\"-\"*10)\n",
    "    \n",
    "        for i, batch_data in enumerate(train_loader):\n",
    "            \n",
    "            model.train()\n",
    "            (y, x, x_size) = batch_data\n",
    "            y_pred = model(x, x_size.cpu())\n",
    "            #print(f\"y_pred: {y_pred}, y_target: {y}\")\n",
    "            loss = loss_function(y_pred, y)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            losses.append(loss)\n",
    "            \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        print(\"Epoch: {}, train loss: {:.4f}\".format(epoch+1, running_loss/len(losses)))\n",
    "        with torch.no_grad():\n",
    "            for i, batch_data in enumerate(val_loader):\n",
    "                (y, x, x_size) = batch_data\n",
    "                y, x, x_size = y.to(device), x.to(device), x_size.to(device)\n",
    "                \n",
    "                y_pred = model(x, x_size.cpu())\n",
    "                loss = loss_function(y_pred, y)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        print(\"Epoch: {}, validation loss: {:.4f}\".format(epoch+1, val_loss/len(val_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[188], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(model, train_loader, val_loader, torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49mcross_entropy, optimizer, NUM_EPOCHS, DEVICE)\n",
      "Cell \u001b[0;32mIn[187], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, loss_function, optim, epochs, device)\u001b[0m\n\u001b[1;32m     17\u001b[0m optim\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     18\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 19\u001b[0m optim\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     21\u001b[0m running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     22\u001b[0m losses\u001b[39m.\u001b[39mappend(loss)\n",
      "File \u001b[0;32m~/ml_accel/lib/python3.9/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    374\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/ml_accel/lib/python3.9/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/ml_accel/lib/python3.9/site-packages/torch/optim/adam.py:163\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    152\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    154\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    155\u001b[0m         group,\n\u001b[1;32m    156\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    161\u001b[0m         state_steps)\n\u001b[0;32m--> 163\u001b[0m     adam(\n\u001b[1;32m    164\u001b[0m         params_with_grad,\n\u001b[1;32m    165\u001b[0m         grads,\n\u001b[1;32m    166\u001b[0m         exp_avgs,\n\u001b[1;32m    167\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    168\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    169\u001b[0m         state_steps,\n\u001b[1;32m    170\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    171\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    172\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    173\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    174\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    175\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    176\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    177\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    178\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    179\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    180\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    181\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    182\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    185\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/ml_accel/lib/python3.9/site-packages/torch/optim/adam.py:311\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 311\u001b[0m func(params,\n\u001b[1;32m    312\u001b[0m      grads,\n\u001b[1;32m    313\u001b[0m      exp_avgs,\n\u001b[1;32m    314\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    315\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    316\u001b[0m      state_steps,\n\u001b[1;32m    317\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    318\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    319\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    320\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    321\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    322\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    323\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    324\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    325\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    326\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    327\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m~/ml_accel/lib/python3.9/site-packages/torch/optim/adam.py:556\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    552\u001b[0m bias_correction2 \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta2 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m _get_value(step) \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m device_state_steps]\n\u001b[1;32m    554\u001b[0m step_size \u001b[39m=\u001b[39m _stack_if_compiling([(lr \u001b[39m/\u001b[39m bc) \u001b[39m*\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m bc \u001b[39min\u001b[39;00m bias_correction1])\n\u001b[0;32m--> 556\u001b[0m bias_correction2_sqrt \u001b[39m=\u001b[39m [_dispatch_sqrt(bc) \u001b[39mfor\u001b[39;00m bc \u001b[39min\u001b[39;00m bias_correction2]\n\u001b[1;32m    558\u001b[0m \u001b[39mif\u001b[39;00m amsgrad:\n\u001b[1;32m    559\u001b[0m     \u001b[39m# Maintains the maximum of all 2nd moment running avg. till now\u001b[39;00m\n\u001b[1;32m    560\u001b[0m     torch\u001b[39m.\u001b[39m_foreach_maximum_(device_max_exp_avg_sqs, device_exp_avg_sqs)\n",
      "File \u001b[0;32m~/ml_accel/lib/python3.9/site-packages/torch/optim/adam.py:556\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    552\u001b[0m bias_correction2 \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta2 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m _get_value(step) \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m device_state_steps]\n\u001b[1;32m    554\u001b[0m step_size \u001b[39m=\u001b[39m _stack_if_compiling([(lr \u001b[39m/\u001b[39m bc) \u001b[39m*\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m bc \u001b[39min\u001b[39;00m bias_correction1])\n\u001b[0;32m--> 556\u001b[0m bias_correction2_sqrt \u001b[39m=\u001b[39m [_dispatch_sqrt(bc) \u001b[39mfor\u001b[39;00m bc \u001b[39min\u001b[39;00m bias_correction2]\n\u001b[1;32m    558\u001b[0m \u001b[39mif\u001b[39;00m amsgrad:\n\u001b[1;32m    559\u001b[0m     \u001b[39m# Maintains the maximum of all 2nd moment running avg. till now\u001b[39;00m\n\u001b[1;32m    560\u001b[0m     torch\u001b[39m.\u001b[39m_foreach_maximum_(device_max_exp_avg_sqs, device_exp_avg_sqs)\n",
      "File \u001b[0;32m~/ml_accel/lib/python3.9/site-packages/torch/optim/optimizer.py:101\u001b[0m, in \u001b[0;36m_dispatch_sqrt\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39msqrt()\n\u001b[1;32m    100\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[39mreturn\u001b[39;00m math\u001b[39m.\u001b[39msqrt(x)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, train_loader, val_loader, torch.nn.functional.cross_entropy, optimizer, NUM_EPOCHS, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes: \n",
    "\n",
    "Something about the handling of decreasing batch sizes and packed sequences makes our lstm from scratch inefficient at learning when compared to the native torch version. However, working through the implementation and the bugs that came with it helped me better understand the internals of the lstm. What's especially impressive is that using a single layered unidirectional LSTM is much more effective for learning on this task than a 2 layered bidirectional RNN (see `RecurrentNetworks/bidirectionalRNN`)\n",
    "\n",
    "Below, we still make use of our hand crafted LSTM for a non batched, non-packed use case where it should not suffer from its inefficiencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stockLSTM(nn.Module): \n",
    "    def __init__(self, input_dim, hidden_size, output_dim) -> None:\n",
    "        super(stockLSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size \n",
    "        self.lstm = lstm(input_dim, hidden_size, output_dim)\n",
    "        self.output_layer = nn.Linear(hidden_size, output_dim)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        (h, _) = self.lstm(x)\n",
    "        output = self.output_layer(h)\n",
    "        \n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_scratch_model(model, train_loader, val_loader,  loss_function, optim, epochs, device, scheduler, start_decay):\n",
    "    \n",
    "    losses = [] #group losses for loss visualization \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0 \n",
    "        print(\"Epoch %d / %d\" % (epoch+1, epochs))\n",
    "        print(\"-\"*10)\n",
    "        if (epoch > start_decay): \n",
    "            scheduler.step()\n",
    "        \n",
    "\n",
    "        for i, (x, y) in enumerate(train_loader):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss = loss_function(y_pred, y) \n",
    "            running_loss+=loss.item()\n",
    "            optim.zero_grad()\n",
    "            loss.backward(retain_graph=True) #backprop \n",
    "            optim.step() #update weights\n",
    "  \n",
    "        losses.append((running_loss / i))\n",
    "        print(\"Step: {}/{}, current Epoch loss: {:.4f}\".format(i, len(train_loader), (running_loss / i)))\n",
    "\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for i, (x,y) in enumerate(val_loader):\n",
    "                y, x,  = y.to(device), x.to(device) \n",
    "                \n",
    "                y_pred = model(x)\n",
    "                loss = loss_function(y_pred, y)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        print(\"Epoch: {}, validation loss: {:.4f}\".format(epoch+1, val_loss/len(val_loader)))\n",
    "        \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(stock, sequence_length):\n",
    "    # Convert pandas dataframe to numpy array\n",
    "    data_raw = stock.to_numpy()\n",
    "\n",
    "    data = []\n",
    "\n",
    "    # Loop over the stock data to generate sequences of 'sequence_length' consecutive data points\n",
    "    # This is done because RNNs learn to predict data in a sequence from past sequence\n",
    "    for index in range(len(data_raw) - sequence_length):\n",
    "        data.append(data_raw[index: index + sequence_length])\n",
    "\n",
    "    data = np.array(data)\n",
    "    set_size = int(data.shape[0])\n",
    "\n",
    "    # Generate the train data\n",
    "    # x_train is all sequences excluding the last data point from each sequence\n",
    "    x = data[:,:-1,:]\n",
    "    # y_train is the last data point from each sequence\n",
    "    y = data[:,-1,:]\n",
    "    \n",
    "\n",
    "    # Return the train and test data\n",
    "    return [x, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_df = pd.read_csv('IBM.csv')\n",
    "ibm_df['Date'] = pd.to_datetime(ibm_df['Date'])\n",
    "ibm_df.set_index('Date',inplace=True)\n",
    "ibm_df = ibm_df[['Close']]\n",
    "\n",
    "# Get the number of rows in the DataFrame\n",
    "num_rows = ibm_df.shape[0]\n",
    "\n",
    "# Compute the split point\n",
    "split_point = int(num_rows*0.8)\n",
    "\n",
    "# Split the DataFrame\n",
    "train_val_df = ibm_df.iloc[:split_point]\n",
    "test_df = ibm_df.iloc[split_point:]\n",
    "val_split = int((train_val_df.shape[0])*0.8)\n",
    "train_df = train_val_df.iloc[:val_split]\n",
    "val_df = train_val_df[val_split:]\n",
    "\n",
    "x_train, y_train = load_data(train_df, 10) \n",
    "x_test, y_test = load_data(test_df, 10) \n",
    "x_val, y_val = load_data(val_df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Close\n",
      "Date             \n",
      "2006-01-03  82.06\n",
      "2006-01-04  81.95\n",
      "2006-01-05  82.50\n",
      "2006-01-06  84.95\n",
      "2006-01-09  83.73\n"
     ]
    }
   ],
   "source": [
    "print(train_df.head()) #to ensure no shuffling accidentally occurred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Close\n",
      "Date              \n",
      "2017-12-22  152.50\n",
      "2017-12-26  152.83\n",
      "2017-12-27  153.13\n",
      "2017-12-28  154.04\n",
      "2017-12-29  153.42\n"
     ]
    }
   ],
   "source": [
    "print(test_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train input data shape: (1922, 9, 1), target shape: (1922, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train input data shape: {}, target shape: {}\".format(x_train.shape, y_train.shape)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test input data shape: (594, 9, 1), target shape: (594, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test input data shape: {}, target shape: {}\".format(x_test.shape, y_test.shape)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(x_train).type(torch.Tensor)\n",
    "x_test = torch.from_numpy(x_test).type(torch.Tensor)\n",
    "x_val = torch.from_numpy(x_val).type(torch.Tensor)\n",
    "y_train = torch.from_numpy(y_train).type(torch.Tensor)\n",
    "y_test = torch.from_numpy(y_test).type(torch.Tensor)\n",
    "y_val = torch.from_numpy(y_val).type(torch.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torch.utils.data.TensorDataset(x_train,y_train)\n",
    "test_set = torch.utils.data.TensorDataset(x_test,y_test)\n",
    "val_set = torch.utils.data.TensorDataset(x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 200\n",
    "BATCH_SIZE = 32 \n",
    "LEARNING_RATE = 0.1\n",
    "INPUT_DIM = 1 \n",
    "OUTPUT_DIM = 1 \n",
    "HIDDEN_DIM = 16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, \n",
    "                                           batch_size=BATCH_SIZE, \n",
    "                                           shuffle=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, \n",
    "                                          batch_size=BATCH_SIZE, \n",
    "                                          shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_set, \n",
    "                                          batch_size=BATCH_SIZE, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = stockLSTM(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "DECAY_FACTOR = 0.001\n",
    "DECAY_EPOCHS = 50\n",
    "START_DECAY_EPOCH = 50\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=DECAY_EPOCHS, gamma=DECAY_FACTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 200\n",
      "----------\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aryaman.pandya/ml_accel/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning:\n",
      "\n",
      "size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "\n",
      "/home/aryaman.pandya/ml_accel/lib/python3.9/site-packages/torch/autograd/__init__.py:251: UserWarning:\n",
      "\n",
      "Error detected in AddmmBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/usr/local/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/local/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/aryaman.pandya/ml_accel/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/aryaman.pandya/ml_accel/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/aryaman.pandya/ml_accel/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 736, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/aryaman.pandya/ml_accel/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/local/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/local/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/local/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/aryaman.pandya/ml_accel/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/aryaman.pandya/ml_accel/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/aryaman.pandya/ml_accel/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/aryaman.pandya/ml_accel/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/aryaman.pandya/ml_accel/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/aryaman.pandya/ml_accel/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/aryaman.pandya/ml_accel/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/aryaman.pandya/ml_accel/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/aryaman.pandya/ml_accel/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/aryaman.pandya/ml_accel/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/aryaman.pandya/ml_accel/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/aryaman.pandya/ml_accel/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_92548/4244450665.py\", line 1, in <module>\n",
      "    losses = train_scratch_model(model=model, train_loader=train_loader, val_loader=val_loader, loss_function=torch.nn.MSELoss(size_average=True), optim=optimizer, epochs=NUM_EPOCHS, device=device, scheduler=scheduler, \\\n",
      "  File \"/tmp/ipykernel_92548/354532160.py\", line 16, in train_scratch_model\n",
      "    y_pred = model(x)\n",
      "  File \"/home/aryaman.pandya/ml_accel/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/aryaman.pandya/ml_accel/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_92548/2162578010.py\", line 11, in forward\n",
      "    (h, _) = self.lstm(x)\n",
      "  File \"/home/aryaman.pandya/ml_accel/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/aryaman.pandya/ml_accel/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_92548/3016655812.py\", line 67, in forward\n",
      "    (h_out, c_out) = self.lstm_cell_list[layer](input, h_in[layer], c_in[layer])  # if first hidden layer, use input\n",
      "  File \"/home/aryaman.pandya/ml_accel/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/aryaman.pandya/ml_accel/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_92548/172890513.py\", line 28, in forward\n",
      "    gates = self.x2h(x) + self.h2h(hx)\n",
      "  File \"/home/aryaman.pandya/ml_accel/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/aryaman.pandya/ml_accel/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/aryaman.pandya/ml_accel/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      " (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:114.)\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [32, 16]], which is output 0 of AsStridedBackward0, is at version 9; expected version 8 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[349], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m losses \u001b[39m=\u001b[39m train_scratch_model(model\u001b[39m=\u001b[39;49mmodel, train_loader\u001b[39m=\u001b[39;49mtrain_loader, val_loader\u001b[39m=\u001b[39;49mval_loader, loss_function\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mMSELoss(size_average\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m), optim\u001b[39m=\u001b[39;49moptimizer, epochs\u001b[39m=\u001b[39;49mNUM_EPOCHS, device\u001b[39m=\u001b[39;49mdevice, scheduler\u001b[39m=\u001b[39;49mscheduler, \\\n\u001b[1;32m      2\u001b[0m     start_decay\u001b[39m=\u001b[39;49mSTART_DECAY_EPOCH)\n",
      "Cell \u001b[0;32mIn[334], line 20\u001b[0m, in \u001b[0;36mtrain_scratch_model\u001b[0;34m(model, train_loader, val_loader, loss_function, optim, epochs, device, scheduler, start_decay)\u001b[0m\n\u001b[1;32m     18\u001b[0m     running_loss\u001b[39m+\u001b[39m\u001b[39m=\u001b[39mloss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     19\u001b[0m     optim\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 20\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward(retain_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m) \u001b[39m#backprop \u001b[39;00m\n\u001b[1;32m     21\u001b[0m     optim\u001b[39m.\u001b[39mstep() \u001b[39m#update weights\u001b[39;00m\n\u001b[1;32m     23\u001b[0m losses\u001b[39m.\u001b[39mappend((running_loss \u001b[39m/\u001b[39m i))\n",
      "File \u001b[0;32m~/ml_accel/lib/python3.9/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/ml_accel/lib/python3.9/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [32, 16]], which is output 0 of AsStridedBackward0, is at version 9; expected version 8 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "losses = train_scratch_model(model=model, train_loader=train_loader, val_loader=val_loader, loss_function=torch.nn.MSELoss(size_average=True), optim=optimizer, epochs=NUM_EPOCHS, device=device, scheduler=scheduler, \\\n",
    "    start_decay=START_DECAY_EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes \n",
    "After increasing the learning rate and de-coupling the output layer from the original lstm neural network we see performance boosts that get the LSTM to actually learn. The RNN still seems to outperform the LSTM on this task, but such short window inputs are not where LSTMs thrive. They thrive when they can capture long term dependencies that RNNs cannot. We will be exploring this idea further in the future. \n",
    "\n",
    "We also don't want an overfitted model and are trying to detect a complex pattern from a simplified input sequence. Considering this, the network performs pretty well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "epochs = list(range(len(losses)))\n",
    "\n",
    "fig = go.Figure(data=go.Scatter(x=epochs, y=losses, mode='lines+markers', name='Train'))\n",
    "\n",
    "fig.update_layout(title='Training Loss per Epoch',\n",
    "                   xaxis_title='Epoch',\n",
    "                   yaxis_title='Loss')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [] \n",
    "predicted = []\n",
    "\n",
    "model.eval()\n",
    "for i, (x, y) in enumerate(test_loader):\n",
    "        \n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    y_pred = model(x)\n",
    "    predicted.append(y_pred.cpu().detach().numpy())\n",
    "    targets.append(y.cpu().detach().numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 264.458984375\n",
      "Root Mean Squared Error (RMSE): 16.262195587158203\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "target_long_array = np.concatenate(targets)\n",
    "predicted_long_array = np.concatenate(predicted)\n",
    "\n",
    "mse = mean_squared_error(target_long_array, predicted_long_array)\n",
    "print(f'Mean Squared Error (MSE): {mse}')\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = target_long_array.tolist()\n",
    "predicted_list = predicted_long_array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(predicted_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Add the targets and predictions to the plot\n",
    "ax.plot(target_list, label='Targets')\n",
    "ax.plot(predicted_list, label='Predictions')\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('Index')\n",
    "ax.set_ylabel('Values')\n",
    "ax.set_title('Targets and Predictions')\n",
    "\n",
    "# Add a legend\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_accel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
