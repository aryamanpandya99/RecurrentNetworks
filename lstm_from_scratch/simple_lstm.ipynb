{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long short term memory\n",
    "\n",
    "We previously explored RNNs, neural networks that are able to propagate some hidden state through a rolled out version of itself. A major problem with RNNs is exploding or vanishing gradients. Gradient clipping solves the exploding gradient problem, but the vanishing gradient problem is harder to solve. LSTMs propose a different architecture which benefits from a hidden state like RNNs, but mitigates the vanishing gradient problem. Another issue RNNs have is that the hidden state often forgets information from a while ago in the sequence and is more biased towards more recent tokens. LSTMs also address this issue with their gated structure. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.nn.utils.rnn import PackedSequence\n",
    "import torch.nn.functional\n",
    "from torch.utils.data import random_split\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM model defintion\n",
    "The goal here is to build a substitute for the torch.nn.rnn.lstm module. This should be able to handle packed sequences and batched data the same way the source code for that module does. For now, does not need to have multiple layers or be bidirectional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm(nn.Module): \n",
    "    def __init__(self, input_size, hidden_dim, output_dim=1) -> None:\n",
    "        super().__init__()\n",
    "        self.input_dim = input_size\n",
    "        self.hidden_dim  = hidden_dim\n",
    "        \n",
    "        self.forget_gate = nn.Sequential(\n",
    "            nn.Linear(input_size+hidden_dim, hidden_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.input_gate = nn.Sequential(\n",
    "            nn.Linear(input_size+hidden_dim, hidden_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.input_node = nn.Sequential(\n",
    "            nn.Linear(input_size+hidden_dim, hidden_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.output_gate = nn.Sequential(\n",
    "            nn.Linear(input_size+hidden_dim, hidden_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        # this output layer can be fancier if needed by the use case\n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, h_in=None, c_in=None):\n",
    "\n",
    "        if isinstance(x, PackedSequence):\n",
    "            input, batch_sizes, sorted_indices, unsorted_indices = x\n",
    "            max_batch_size = batch_sizes[0]\n",
    "            if h_in is None: \n",
    "                h_in = self.init_h(max_batch_size, x)\n",
    "                c_in = self.init_h(max_batch_size, x)\n",
    "        \n",
    "            data_offset = 0\n",
    "            outputs = []\n",
    "            for batch_size in batch_sizes:\n",
    "                current_input = input[data_offset:data_offset + batch_size]\n",
    "                data_offset += batch_size\n",
    "                current_input = current_input.unsqueeze(0)\n",
    "                if batch_size < max_batch_size: \n",
    "                    h_in[:,batch_size:,:] = 0\n",
    "                    c_in[:,batch_size:,:] = 0\n",
    "                    pad_size = max_batch_size - batch_size\n",
    "                    # Create a tensor of zeros with the padding size\n",
    "                    padding = torch.zeros(1, pad_size, self.hidden_dim, device=current_input.device)\n",
    "                    # Concatenate the padding to the current input\n",
    "                    current_input = torch.cat([current_input, padding], dim=1)\n",
    "                \n",
    "                combined = torch.cat([current_input, h_in], dim=2)\n",
    "                \n",
    "                i_gate_output = self.input_gate(combined)\n",
    "                i_node_output = self.input_node(combined)\n",
    "                o_gate_output = self.output_gate(combined)\n",
    "                f_gate_output = self.forget_gate(combined)\n",
    "\n",
    "                c_out = (f_gate_output * c_in) + (i_node_output * i_gate_output)\n",
    "\n",
    "                h_out = self.tanh(c_out) * o_gate_output\n",
    "                out = self.output_layer(h_out)\n",
    "                h_in = h_out\n",
    "                c_in = c_out\n",
    "                outputs.append(out)\n",
    "\n",
    "                # Handle decreasing batch siz\n",
    "            output_packed = PackedSequence(outputs, batch_sizes, sorted_indices, unsorted_indices)\n",
    "            return output_packed, (h_out, c_out)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            for t in range(x.size(1)):\n",
    "                input = x[:,t,:]\n",
    "                combined = torch.cat([input, h_in], dim=1)\n",
    "                        \n",
    "                i_gate_output = self.input_gate(combined)\n",
    "                i_node_output = self.input_node(combined)\n",
    "                o_gate_output = self.output_gate(combined)\n",
    "                f_gate_output = self.forget_gate(combined)\n",
    "\n",
    "                c_out = (f_gate_output * c_in) + (i_node_output * i_gate_output)\n",
    "                h_out = self.tanh(c_out) * o_gate_output\n",
    "                out = self.output_layer(h_out)\n",
    "                h_in = h_out \n",
    "                c_in = c_out\n",
    "            \n",
    "        return out, (h_out, c_out)\n",
    "    \n",
    "    \n",
    "    def init_h(self, batch_size, sequence_length):\n",
    "        #zero initialization \n",
    "        #alternatives include but not limited to Xavier/Kaiminh initialization\n",
    "        return torch.zeros(batch_size, self.hidden_dim, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm_simplified(nn.Module): \n",
    "    def __init__(self, input_size, hidden_dim, output_dim=1) -> None:\n",
    "        super().__init__()\n",
    "        self.input_dim = input_size\n",
    "        self.hidden_dim  = hidden_dim\n",
    "        \n",
    "        self.x_h = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_dim * 4),\n",
    "        )\n",
    "        self.h_x = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim * 4),\n",
    "        )\n",
    "\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        # this output layer can be fancier if needed by the use case\n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, h_in=None, c_in=None):\n",
    "\n",
    "        if isinstance(x, PackedSequence):\n",
    "            input, batch_sizes, sorted_indices, unsorted_indices = x\n",
    "            max_batch_size = batch_sizes[0]\n",
    "            if h_in is None: \n",
    "                h_in = self.init_h(max_batch_size, x)\n",
    "                c_in = self.init_h(max_batch_size, x)\n",
    "        \n",
    "            data_offset = 0\n",
    "            outputs = []\n",
    "            for batch_size in batch_sizes:\n",
    "                current_input = input[data_offset:data_offset + batch_size]\n",
    "                data_offset += batch_size\n",
    "                current_input = current_input.unsqueeze(0)\n",
    "                if batch_size < max_batch_size: \n",
    "                    h_in[:,batch_size:,:] = 0\n",
    "                    c_in[:,batch_size:,:] = 0\n",
    "                    pad_size = max_batch_size - batch_size\n",
    "                    # Create a tensor of zeros with the padding size\n",
    "                    padding = torch.zeros(1, pad_size, self.hidden_dim, device=current_input.device)\n",
    "                    # Concatenate the padding to the current input\n",
    "                    current_input = torch.cat([current_input, padding], dim=1)\n",
    "                \n",
    "                gates = self.x_h(current_input) +  self.h_x(h_in)\n",
    "                input_gate, forget_gate, input_node, output_gate = gates.chunk(4, 2)\n",
    "                i_gate_output = torch.sigmoid(input_gate)\n",
    "                i_node_output = torch.tanh(input_node)\n",
    "                o_gate_output = torch.sigmoid(output_gate)\n",
    "                f_gate_output = torch.sigmoid(forget_gate)\n",
    "                \n",
    "                c_out = (f_gate_output * c_in) + (i_node_output * i_gate_output)\n",
    "\n",
    "                h_out = self.tanh(c_out) * o_gate_output\n",
    "                out = self.output_layer(h_out)\n",
    "                h_in = h_out\n",
    "                c_in = c_out\n",
    "                outputs.append(out)\n",
    "\n",
    "                # Handle decreasing batch siz\n",
    "\n",
    "\n",
    "            output_packed = PackedSequence(outputs, batch_sizes, sorted_indices, unsorted_indices)\n",
    "            return output_packed, h_out, c_out\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            for t in range(x.size(1)):\n",
    "                input = x[:,t,:]\n",
    "                gates = self.x_h(input) +  self.h_x(h_in)\n",
    "                input_gate, forget_gate, input_node, output_gate = gates.chunk(4, 1)\n",
    "                i_gate_output = torch.sigmoid(input_gate)\n",
    "                i_node_output = torch.tanh(input_node)\n",
    "                o_gate_output = torch.sigmoid(output_gate)\n",
    "                f_gate_output = torch.sigmoid(forget_gate)\n",
    "                \n",
    "                c_out = (f_gate_output * c_in) + (i_node_output * i_gate_output)\n",
    "\n",
    "                h_out = self.tanh(c_out) * o_gate_output\n",
    "                out = self.output_layer(h_out)\n",
    "                h_in = h_out\n",
    "                c_in = c_out\n",
    "            \n",
    "        return out, (h_out, c_out)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def init_h(self, batch_size, sequence_length):\n",
    "        #zero initialization \n",
    "        #alternatives include but not limited to Xavier/Kaiminh initialization\n",
    "        return torch.zeros(batch_size, self.hidden_dim, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "class newsLSTM(nn.Module): \n",
    "    def __init__(self, vocab_size, embed_size, hidden_size) -> None:\n",
    "        super(newsLSTM, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        self.hidden_size = hidden_size \n",
    "        self.lstm = nn.LSTM(embed_size, \n",
    "                           hidden_size,\n",
    "                           batch_first=True)\n",
    "        \n",
    "        self.hidden2label = nn.Linear(hidden_size, 4)\n",
    "        self.dropoutLayer = nn.Dropout(p=0.5)\n",
    "\n",
    "\n",
    "    def forward(self, x, x_len):\n",
    "        embedded = self.encoder(x)\n",
    "        x_packed = nn.utils.rnn.pack_padded_sequence(embedded, x_len, batch_first=True, enforce_sorted=False)\n",
    "        output, (h_t, c_t) = self.lstm(x_packed)  # Pass the initial hidden state 'h' to the RNN   \n",
    "        # hidden = self.dropout(torch.cat((h_t[-2,:,:], h_t[-1,:,:]), dim=1))     \n",
    "        hidden = self.dropoutLayer(h_t.squeeze())\n",
    "        \n",
    "        # Linear layer and softmax\n",
    "        label_space = self.hidden2label(hidden)\n",
    "        \n",
    "        return label_space\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat the exact same news classification task performed by in the bidirectionalRNN subdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = AG_NEWS(split='train')\n",
    "\n",
    "# Convert to list to enable random splitting\n",
    "train_dataset = list(train_iter)\n",
    "\n",
    "#80-20 train-val split \n",
    "train_size = int(len(train_dataset) * 0.8)  \n",
    "val_size = len(train_dataset) - train_size  \n",
    "train_data, val_data = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "VOCAB_SIZE = 5000\n",
    "\n",
    "# Build vocab based on the train_data\n",
    "train_data_iter = (text for _, text in train_data)\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_data_iter), specials=[\"<unk>\"], max_tokens=VOCAB_SIZE)\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,\n",
       " 'New Trojan Sends Spam (PC World) PC World - Virus hijacks PCs and uses them to send short message spam to mobile phones.')"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2143, 1676, 4877, 0]"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['word', 'probably', 'unknown', 'gibberish'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spike']"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.lookup_tokens([4999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "    \n",
    "    # Sort the batch in the descending order\n",
    "    batch.sort(key=lambda x: len(x[1]), reverse=True)\n",
    "    \n",
    "    for _label, _text in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        lengths.append(processed_text.size(0))\n",
    "        \n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    lengths = torch.tensor(lengths, dtype=torch.int64)\n",
    "    \n",
    "    # Pad sequences\n",
    "    text_list = pad_sequence(text_list, batch_first=True)\n",
    "    \n",
    "    return label_list.to(device), text_list.to(device), lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size = 8, shuffle = True, collate_fn = collate_batch)\n",
    "val_loader = DataLoader(val_data, batch_size = 8, shuffle = False, collate_fn = collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "\n",
    "# Inspect the shape of the input data\n",
    "input_data = batch[1]  # Assuming the input data is the first element of the batch\n",
    "input_shape = input_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 77])"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =  torch.ones(5, 50)\n",
    "a =  torch.ones(5, 50)\n",
    "a =  torch.ones(5, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Softmax(dim=1)\n",
    "input = torch.randn(2, 3)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5739, -0.3782,  0.4222],\n",
       "        [ 1.2310,  0.1912, -1.2395]])"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2031, 0.2470, 0.5499],\n",
       "        [0.6954, 0.2458, 0.0588]])"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 2, 2, 0, 3, 1, 1], device='cuda:0')\n",
      "torch.Size([8, 77])\n"
     ]
    }
   ],
   "source": [
    "print(batch[0])\n",
    "print(batch[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10\n",
    "DROPOUT = 0.5\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "EMBEDDING_DIM = 128\n",
    "BIDIRECTIONAL = True\n",
    "HIDDEN_DIM = 128\n",
    "NUM_LAYERS = 2\n",
    "OUTPUT_DIM = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = newsLSTM(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM)\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, loss_function, optim, epochs, device):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        losses = [] #group losses for loss visualization \n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "        print(\"Epoch %d / %d\" % (epoch+1, epochs))\n",
    "        print(\"-\"*10)\n",
    "    \n",
    "        for i, batch_data in enumerate(train_loader):\n",
    "            \n",
    "            model.train()\n",
    "            (y, x, x_size) = batch_data\n",
    "            y_pred = model(x, x_size.cpu())\n",
    "            #print(f\"y_pred: {y_pred}, y_target: {y}\")\n",
    "            loss = loss_function(y_pred, y)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            losses.append(loss)\n",
    "            \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        print(\"Epoch: {}, train loss: {:.4f}\".format(epoch+1, running_loss/len(losses)))\n",
    "        with torch.no_grad():\n",
    "            for i, batch_data in enumerate(val_loader):\n",
    "                (y, x, x_size) = batch_data\n",
    "                y, x, x_size = y.to(device), x.to(device), x_size.to(device)\n",
    "                \n",
    "                y_pred = model(x, x_size.cpu())\n",
    "                loss = loss_function(y_pred, y)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        print(\"Epoch: {}, validation loss: {:.4f}\".format(epoch+1, val_loss/len(val_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10\n",
      "----------\n",
      "Epoch: 1, train loss: 0.4924\n",
      "Epoch: 1, validation loss: 0.3248\n",
      "Epoch 2 / 10\n",
      "----------\n",
      "Epoch: 2, train loss: 0.2818\n",
      "Epoch: 2, validation loss: 0.2689\n",
      "Epoch 3 / 10\n",
      "----------\n",
      "Epoch: 3, train loss: 0.2256\n",
      "Epoch: 3, validation loss: 0.2664\n",
      "Epoch 4 / 10\n",
      "----------\n",
      "Epoch: 4, train loss: 0.1847\n",
      "Epoch: 4, validation loss: 0.2672\n",
      "Epoch 5 / 10\n",
      "----------\n",
      "Epoch: 5, train loss: 0.1512\n",
      "Epoch: 5, validation loss: 0.2711\n",
      "Epoch 6 / 10\n",
      "----------\n",
      "Epoch: 6, train loss: 0.1282\n",
      "Epoch: 6, validation loss: 0.3046\n",
      "Epoch 7 / 10\n",
      "----------\n",
      "Epoch: 7, train loss: 0.1090\n",
      "Epoch: 7, validation loss: 0.3090\n",
      "Epoch 8 / 10\n",
      "----------\n",
      "Epoch: 8, train loss: 0.0941\n",
      "Epoch: 8, validation loss: 0.3336\n",
      "Epoch 9 / 10\n",
      "----------\n",
      "Epoch: 9, train loss: 0.0827\n",
      "Epoch: 9, validation loss: 0.3571\n",
      "Epoch 10 / 10\n",
      "----------\n",
      "Epoch: 10, train loss: 0.0744\n",
      "Epoch: 10, validation loss: 0.3712\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, val_loader, torch.nn.functional.cross_entropy, optimizer, NUM_EPOCHS, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes: \n",
    "\n",
    "Something about the handling of decreasing batch sizes and packed sequences makes our lstm from scratch inefficient at learning when compared to the native torch version. However, working through the implementation and the bugs that came with it helped me better understand the internals of the lstm. What's especially impressive is that using a single layered unidirectional LSTM is much more effective for learning on this task than a 2 layered bidirectional RNN (see `RecurrentNetworks/bidirectionalRNN`)\n",
    "\n",
    "Below, we still make use of our hand crafted LSTM for a non batched, non-packed use case where it should not suffer from its inefficiencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_scratch_model(model, data_loader, loss_function, optim, epochs, device, scheduler, start_decay):\n",
    "    \n",
    "    losses = [] #group losses for loss visualization \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0 \n",
    "        print(\"Epoch %d / %d\" % (epoch+1, epochs))\n",
    "        print(\"-\"*10)\n",
    "        if (epoch > start_decay): \n",
    "            scheduler.step()\n",
    "        \n",
    "\n",
    "        for i, (x, y) in enumerate(data_loader):\n",
    "            h_s = model.init_h(x.shape[0], x.shape[1]).to(device) \n",
    "            c_s = model.init_h(x.shape[0], x.shape[1]).to(device) \n",
    "            \n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            y_pred, (h_out, c_out) = model(x, h_s, c_s)\n",
    "            \n",
    "            h_s = h_out\n",
    "            c_s = c_out\n",
    "            \n",
    "            loss = loss_function(y_pred, y) \n",
    "            running_loss+=loss.item()\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            loss.backward(retain_graph=True) #backprop \n",
    "            optim.step() #update weights\n",
    "  \n",
    "        losses.append((running_loss / i))\n",
    "        print(\"Step: {}/{}, current Epoch loss: {:.4f}\".format(i, len(data_loader), (running_loss / i)))\n",
    "        \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(stock, sequence_length):\n",
    "    # Convert pandas dataframe to numpy array\n",
    "    data_raw = stock.to_numpy()\n",
    "\n",
    "    data = []\n",
    "\n",
    "    # Loop over the stock data to generate sequences of 'sequence_length' consecutive data points\n",
    "    # This is done because RNNs learn to predict data in a sequence from past sequence\n",
    "    for index in range(len(data_raw) - sequence_length):\n",
    "        data.append(data_raw[index: index + sequence_length])\n",
    "\n",
    "    data = np.array(data)\n",
    "    set_size = int(data.shape[0])\n",
    "\n",
    "    # Generate the train data\n",
    "    # x_train is all sequences excluding the last data point from each sequence\n",
    "    x = data[:,:-1,:]\n",
    "    # y_train is the last data point from each sequence\n",
    "    y = data[:,-1,:]\n",
    "    \n",
    "\n",
    "    # Return the train and test data\n",
    "    return [x, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_df = pd.read_csv('IBM.csv')\n",
    "ibm_df['Date'] = pd.to_datetime(ibm_df['Date'])\n",
    "ibm_df.set_index('Date',inplace=True)\n",
    "ibm_df = ibm_df[['Close']]\n",
    "\n",
    "# Get the number of rows in the DataFrame\n",
    "num_rows = ibm_df.shape[0]\n",
    "\n",
    "# Compute the split point\n",
    "split_point = int(num_rows*0.8)\n",
    "\n",
    "# Split the DataFrame\n",
    "train_df = ibm_df.iloc[:split_point]\n",
    "test_df = ibm_df.iloc[split_point:]\n",
    "\n",
    "x_train, y_train = load_data(train_df, 10) \n",
    "x_test, y_test = load_data(test_df, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Close\n",
      "Date             \n",
      "2006-01-03  82.06\n",
      "2006-01-04  81.95\n",
      "2006-01-05  82.50\n",
      "2006-01-06  84.95\n",
      "2006-01-09  83.73\n"
     ]
    }
   ],
   "source": [
    "print(train_df.head()) #to ensure no shuffling accidentally occurred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Close\n",
      "Date              \n",
      "2017-12-22  152.50\n",
      "2017-12-26  152.83\n",
      "2017-12-27  153.13\n",
      "2017-12-28  154.04\n",
      "2017-12-29  153.42\n"
     ]
    }
   ],
   "source": [
    "print(test_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train input data shape: (2406, 9, 1), target shape: (2406, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train input data shape: {}, target shape: {}\".format(x_train.shape, y_train.shape)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test input data shape: (594, 9, 1), target shape: (594, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test input data shape: {}, target shape: {}\".format(x_test.shape, y_test.shape)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(x_train).type(torch.Tensor)\n",
    "x_test = torch.from_numpy(x_test).type(torch.Tensor)\n",
    "y_train = torch.from_numpy(y_train).type(torch.Tensor)\n",
    "y_test = torch.from_numpy(y_test).type(torch.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torch.utils.data.TensorDataset(x_train,y_train)\n",
    "test_set = torch.utils.data.TensorDataset(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 1000\n",
    "BATCH_SIZE = 32 \n",
    "LEARNING_RATE = 3e-4\n",
    "INPUT_DIM = 1 \n",
    "OUTPUT_DIM = 1 \n",
    "HIDDEN_DIM = 32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, \n",
    "                                           batch_size=BATCH_SIZE, \n",
    "                                           shuffle=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, \n",
    "                                          batch_size=BATCH_SIZE, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm(INPUT_DIM, HIDDEN_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "DECAY_FACTOR = 0.1\n",
    "DECAY_EPOCHS = 20\n",
    "START_DECAY_EPOCH = 50\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=DECAY_EPOCHS, gamma=DECAY_FACTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aryaman.pandya/ml_accel/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 22668.2415\n",
      "Epoch 2 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 22490.7631\n",
      "Epoch 3 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 22266.2376\n",
      "Epoch 4 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 22027.0859\n",
      "Epoch 5 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 21855.1477\n",
      "Epoch 6 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 21558.8710\n",
      "Epoch 7 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 21275.4812\n",
      "Epoch 8 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 21048.9460\n",
      "Epoch 9 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 20879.6527\n",
      "Epoch 10 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 20650.5112\n",
      "Epoch 11 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 20441.2133\n",
      "Epoch 12 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 20247.0574\n",
      "Epoch 13 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 20010.6914\n",
      "Epoch 14 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 19806.5432\n",
      "Epoch 15 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 19591.0042\n",
      "Epoch 16 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 19388.7289\n",
      "Epoch 17 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 19214.2528\n",
      "Epoch 18 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 19046.4883\n",
      "Epoch 19 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 18883.3341\n",
      "Epoch 20 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 18723.7606\n",
      "Epoch 21 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 18567.1400\n",
      "Epoch 22 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 18413.0446\n",
      "Epoch 23 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 18261.1642\n",
      "Epoch 24 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 18111.2647\n",
      "Epoch 25 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 17963.1599\n",
      "Epoch 26 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 17816.7036\n",
      "Epoch 27 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 17671.7744\n",
      "Epoch 28 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 17528.2721\n",
      "Epoch 29 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 17386.1114\n",
      "Epoch 30 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 17245.2203\n",
      "Epoch 31 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 17105.5363\n",
      "Epoch 32 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 16967.0058\n",
      "Epoch 33 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 16823.7849\n",
      "Epoch 34 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 16633.7005\n",
      "Epoch 35 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 16479.4297\n",
      "Epoch 36 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 16332.3384\n",
      "Epoch 37 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 16188.6522\n",
      "Epoch 38 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 16047.3334\n",
      "Epoch 39 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 15907.8980\n",
      "Epoch 40 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 15770.0694\n",
      "Epoch 41 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 15633.6676\n",
      "Epoch 42 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 15498.5675\n",
      "Epoch 43 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 15364.6774\n",
      "Epoch 44 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 15231.9247\n",
      "Epoch 45 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 15100.2541\n",
      "Epoch 46 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 14969.6188\n",
      "Epoch 47 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 14839.9808\n",
      "Epoch 48 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 14711.3075\n",
      "Epoch 49 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 14583.5715\n",
      "Epoch 50 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 14456.7493\n",
      "Epoch 51 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 14330.8198\n",
      "Epoch 52 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 14205.7643\n",
      "Epoch 53 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 14081.5664\n",
      "Epoch 54 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 13958.2112\n",
      "Epoch 55 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 13835.6871\n",
      "Epoch 56 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 13713.9807\n",
      "Epoch 57 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 13593.0823\n",
      "Epoch 58 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 13472.9821\n",
      "Epoch 59 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 13346.9331\n",
      "Epoch 60 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 13185.1868\n",
      "Epoch 61 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 13051.0750\n",
      "Epoch 62 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 12922.9362\n",
      "Epoch 63 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 12797.7028\n",
      "Epoch 64 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 12674.5015\n",
      "Epoch 65 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 12552.9275\n",
      "Epoch 66 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 12432.7477\n",
      "Epoch 67 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 12313.8153\n",
      "Epoch 68 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 12196.0292\n",
      "Epoch 69 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 12079.3168\n",
      "Epoch 70 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11963.6235\n",
      "Epoch 71 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11902.2331\n",
      "Epoch 72 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11890.7523\n",
      "Epoch 73 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11879.2515\n",
      "Epoch 74 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11867.7329\n",
      "Epoch 75 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11856.1967\n",
      "Epoch 76 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11844.6450\n",
      "Epoch 77 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11833.0784\n",
      "Epoch 78 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11821.4978\n",
      "Epoch 79 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11809.9051\n",
      "Epoch 80 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11798.3011\n",
      "Epoch 81 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11786.6879\n",
      "Epoch 82 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11775.0644\n",
      "Epoch 83 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11763.4344\n",
      "Epoch 84 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11751.7967\n",
      "Epoch 85 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11740.1535\n",
      "Epoch 86 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11728.5054\n",
      "Epoch 87 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11716.8535\n",
      "Epoch 88 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11705.1984\n",
      "Epoch 89 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11693.5411\n",
      "Epoch 90 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11681.8806\n",
      "Epoch 91 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11675.6580\n",
      "Epoch 92 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11674.4918\n",
      "Epoch 93 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11673.3247\n",
      "Epoch 94 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11672.1563\n",
      "Epoch 95 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11670.9876\n",
      "Epoch 96 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11669.8176\n",
      "Epoch 97 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11668.6471\n",
      "Epoch 98 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11667.4759\n",
      "Epoch 99 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11666.3029\n",
      "Epoch 100 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11665.1277\n",
      "Epoch 101 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11663.9510\n",
      "Epoch 102 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11662.7734\n",
      "Epoch 103 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11661.5951\n",
      "Epoch 104 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11660.4168\n",
      "Epoch 105 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11659.2385\n",
      "Epoch 106 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11658.0598\n",
      "Epoch 107 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11656.8806\n",
      "Epoch 108 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11655.7008\n",
      "Epoch 109 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11654.5199\n",
      "Epoch 110 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11653.3383\n",
      "Epoch 111 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11652.7042\n",
      "Epoch 112 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11652.5843\n",
      "Epoch 113 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11652.4645\n",
      "Epoch 114 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11652.3446\n",
      "Epoch 115 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11652.2245\n",
      "Epoch 116 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11652.1047\n",
      "Epoch 117 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11651.9848\n",
      "Epoch 118 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11651.8648\n",
      "Epoch 119 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11651.7449\n",
      "Epoch 120 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11651.6250\n",
      "Epoch 121 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11651.5051\n",
      "Epoch 122 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11651.3851\n",
      "Epoch 123 / 1000\n",
      "----------\n",
      "Step: 75/76, current Epoch loss: 11651.2652\n",
      "Epoch 124 / 1000\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[653], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m losses \u001b[39m=\u001b[39m train_scratch_model(model\u001b[39m=\u001b[39;49mmodel, data_loader\u001b[39m=\u001b[39;49mtrain_loader, loss_function\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mMSELoss(size_average\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m), optim\u001b[39m=\u001b[39;49moptimizer, epochs\u001b[39m=\u001b[39;49mNUM_EPOCHS, device\u001b[39m=\u001b[39;49mdevice, scheduler\u001b[39m=\u001b[39;49mscheduler, \\\n\u001b[1;32m      2\u001b[0m     start_decay\u001b[39m=\u001b[39;49mSTART_DECAY_EPOCH)\n",
      "Cell \u001b[0;32mIn[638], line 13\u001b[0m, in \u001b[0;36mtrain_scratch_model\u001b[0;34m(model, data_loader, loss_function, optim, epochs, device, scheduler, start_decay)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mif\u001b[39;00m (epoch \u001b[39m>\u001b[39m start_decay): \n\u001b[1;32m     10\u001b[0m     scheduler\u001b[39m.\u001b[39mstep()\n\u001b[0;32m---> 13\u001b[0m \u001b[39mfor\u001b[39;00m i, (x, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(data_loader):\n\u001b[1;32m     14\u001b[0m     h_s \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39minit_h(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], x\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mto(device) \n\u001b[1;32m     15\u001b[0m     c_s \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39minit_h(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], x\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mto(device) \n",
      "File \u001b[0;32m~/ml_accel/lib/python3.9/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/ml_accel/lib/python3.9/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/ml_accel/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/ml_accel/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/ml_accel/lib/python3.9/site-packages/torch/utils/data/dataset.py:208\u001b[0m, in \u001b[0;36mTensorDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index):\n\u001b[0;32m--> 208\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39;49m(tensor[index] \u001b[39mfor\u001b[39;00m tensor \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtensors)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = train_scratch_model(model=model, data_loader=train_loader, loss_function=torch.nn.MSELoss(size_average=True), optim=optimizer, epochs=NUM_EPOCHS, device=device, scheduler=scheduler, \\\n",
    "    start_decay=START_DECAY_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_accel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
