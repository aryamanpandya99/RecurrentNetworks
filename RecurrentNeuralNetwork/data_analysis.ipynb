{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Aryaman Pandya \n",
    "Sequential Machine Learning \n",
    "Building a Vanilla RNN \n",
    "Model and trainer implementation \n",
    "Following https://github.com/rasbt/deeplearning-models/blob/master/pytorch_ipynb/rnn/rnn_bi_multilayer_lstm_own_csv_agnews.ipynb\n",
    "implementation minus the memory unit for now \n",
    "'''\n",
    "import torch \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import plotly\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#Class definition of Vanilla RNN \n",
    "class VanillaRNN(nn.Module): \n",
    "    \n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, output_len, num_layers) -> None:\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        self.hidden_size = hidden_size \n",
    "        self.output_len = output_len \n",
    "        \n",
    "        self.rnn = nn.RNN(input_size=embed_size, hidden_size=hidden_size, num_layers=num_layers, dropout=0.5,\n",
    "                                batch_first=True, bidirectional=True) #graph module to compute next hidden state \n",
    "        \n",
    "        self.hidden2label = nn.Linear(2*hidden_size, 2)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.dropoutLayer = nn.Dropout()\n",
    "\n",
    "    def forward(self, x, text_len):\n",
    "        embedded = self.encoder(x)\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_len)\n",
    "        output, hidden = self.rnn(packed_embedded)  # Pass the initial hidden state 'h' to the RNN\n",
    "        \n",
    "        \n",
    "        # Flatten the output tensor to match the linear layer input size\n",
    "        output = output.contiguous().view(-1, 2 * self.hidden_size)\n",
    "        \n",
    "        # Apply dropout to the flattened output\n",
    "        output = self.dropoutLayer(output)\n",
    "        \n",
    "        # Pass the output through the linear layer\n",
    "        output = self.hidden2label(output)\n",
    "        \n",
    "        # Apply softmax activation to get probabilities\n",
    "        output = self.softmax(output)\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    def init_h(self):\n",
    "        return torch.zeros(1, self.len_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(data_iter, tokenizer):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = (AG_NEWS(split=\"train\"))\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "VOCAB_SIZE = 5000\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"], max_tokens=VOCAB_SIZE)\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "#train_loader = DataLoader(train_iter, batch_size = 8, shuffle = True, collate_fn = collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1770, 0, 0]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['testing', 'absolutegibberish', ',.,.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for _label, _text in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_iter, batch_size = 8, shuffle = True, collate_fn = collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "\n",
    "# Inspect the shape of the input data\n",
    "input_data = batch[1]  # Assuming the input data is the first element of the batch\n",
    "input_shape = input_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   0, 3760,  806,  363,  252,  510,   16,    9,  433,   16,    9,    8,\n",
      "         509,   16,    9, 3760,  806,    0,   11,   40,    0,    0, 3121,    1,\n",
      "           0,    0,  474,  304, 2238,   41, 3174,    0, 3159,    5,    0,    0,\n",
      "         674,   17,  287,    0, 3913, 1807,   80,  428,  672, 2015,   98,    5,\n",
      "          16, 1450,   11,    2,  128,  488,   16,  281,  428,  212,    2, 2159,\n",
      "          34,  394,    6, 3988,   24,   19,    5,   98,    6, 2572, 4754, 3789,\n",
      "          32,    0,  145,    1,    0, 1587, 1793,    7,  127,  426,  351,    3,\n",
      "        1147,   15,    0, 1709, 1587, 2218,   59,    7,    2,  127,  426,    6,\n",
      "           2,  313, 1082,   57,  115,    3, 1117,    0,    3, 3878,    3, 3878,\n",
      "           4,    0,    0,    6,    2, 3552, 1816,    1, 1587,    3,   75,  192,\n",
      "        4757,    2,  353,   48,   97,    8, 4030, 2078, 1880, 3953,    2, 4350,\n",
      "           7, 3644,    3,   35,    0,   24, 1390, 3389,    8,    5, 3578,    6,\n",
      "           0, 4940,    1,    1,    1,    0,   12,    0,   12, 2035,  650,  168,\n",
      "         453,   39, 1712,  183,   67,    0,   19,    2,    0,    0, 2035,    0,\n",
      "           5,  615,  826, 1129, 2478,  264,    1,  370,   12,    9,    0,  583,\n",
      "        2074, 3415,   12,    9,  560,    6, 4009,  123,   23,  288, 4042,   20,\n",
      "           0,  957,  167,    2,    0,    6,    2, 3139,    0, 2049,    4,   39,\n",
      "          81,    0,    1,    0,  620,    0,    0,    2,    0, 1619,   18,    5,\n",
      "           0,    0,  109,   38,    0,    7,    2,    0,  620,   20,    0,    1,\n",
      "        4774,    0, 4024,    0,   66,   30,  258,  170,    3,   45,    5,    0,\n",
      "         962,   29,    0,    0, 1571,    0,  231,  113,    1,    0,  535,  468,\n",
      "         120,    1,    0, 1320, 4341,   29,    0,   13,   31,   14,   31,   15,\n",
      "           2,  184, 1320, 2780,   28, 3360,    5,  468,  120,    1,  248,   82,\n",
      "        4341,    4,    2,  596,    6,    0,   20,    0,    0,    4,    0, 4150,\n",
      "        1748,   66,    2,    0,    3,    0,    8,  171,    1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 50\n",
    "DROPOUT = 0.5\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "EMBEDDING_DIM = 128\n",
    "BIDIRECTIONAL = True\n",
    "HIDDEN_DIM = 256\n",
    "NUM_LAYERS = 2\n",
    "OUTPUT_DIM = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VanillaRNN(vocab_size, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, NUM_LAYERS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_accel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
