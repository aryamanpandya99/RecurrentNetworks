{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Aryaman Pandya \n",
    "Sequential Machine Learning \n",
    "Building a Vanilla RNN \n",
    "Model and trainer implementation \n",
    "Following https://github.com/rasbt/deeplearning-models/blob/master/pytorch_ipynb/rnn/rnn_bi_multilayer_lstm_own_csv_agnews.ipynb\n",
    "implementation minus the memory unit for now \n",
    "'''\n",
    "import torch \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import plotly\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#Class definition of Vanilla RNN \n",
    "class VanillaRNN(nn.Module): \n",
    "    \n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, output_len, num_layers) -> None:\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        self.hidden_size = hidden_size \n",
    "        self.output_len = output_len \n",
    "        \n",
    "        self.rnn = nn.RNN(input_size=embed_size, hidden_size=hidden_size, num_layers=num_layers, dropout=0.5,\n",
    "                                batch_first=True, bidirectional=True) #graph module to compute next hidden state \n",
    "        \n",
    "        self.hidden2label = nn.Linear(2*hidden_size, 2)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.dropoutLayer = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x, x_len):\n",
    "        embedded = self.encoder(x)\n",
    "        x_packed = nn.utils.rnn.pack_padded_sequence(embedded, x_len, batch_first=True, enforce_sorted=False)\n",
    "        output, hidden = self.rnn(x_packed)  # Pass the initial hidden state 'h' to the RNN\n",
    "        \n",
    "        \n",
    "        # Flatten the output tensor to match the linear layer input size\n",
    "        output = output.contiguous().view(-1, 2 * self.hidden_size)\n",
    "        \n",
    "        # Apply dropout to the concatenated hidden state\n",
    "        hidden = self.dropoutLayer(hidden)\n",
    "        \n",
    "        # Linear layer and softmax\n",
    "        label_space = self.hidden2label(hidden)\n",
    "        output_probs = self.softmax(label_space)\n",
    "        \n",
    "        return output_probs\n",
    "\n",
    "    def init_h(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(data_iter, tokenizer):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = (AG_NEWS(split=\"train\"))\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "VOCAB_SIZE = 5000\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"], max_tokens=VOCAB_SIZE)\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "#train_loader = DataLoader(train_iter, batch_size = 8, shuffle = True, collate_fn = collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wreckage']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.lookup_tokens([4999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_batch(batch):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "    \n",
    "    # Sort the batch in the descending order\n",
    "    batch.sort(key=lambda x: len(x[1]), reverse=True)\n",
    "    \n",
    "    for _label, _text in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        lengths.append(processed_text.size(0))\n",
    "        \n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    lengths = torch.tensor(lengths, dtype=torch.int64)\n",
    "    \n",
    "    # Pad sequences\n",
    "    text_list = pad_sequence(text_list, batch_first=True)\n",
    "    \n",
    "    return label_list.to(device), text_list.to(device), lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_iter, batch_size = 8, shuffle = True, collate_fn = collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "\n",
    "# Inspect the shape of the input data\n",
    "input_data = batch[1]  # Assuming the input data is the first element of the batch\n",
    "input_shape = input_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 2, 2, 1, 0, 0, 1], device='cuda:0')\n",
      "tensor([[1880,    3, 4016,    3,    0,  109,    0,   13,   31,   14,   31,   15,\n",
      "            0,   46,   24,    2, 3030,    8,  256,    0, 1882,   72,  256, 3561,\n",
      "            3, 1888,  276,    0, 4016,  643,    0,    0,    0,    6,    0, 2731,\n",
      "            3, 1979,    7,    2,  781,  620,    6,    2,  351,  221,   16, 1201,\n",
      "         1082,    1, 2078, 1880,  212,   32,  313, 1189,   18,    5, 1859,    3,\n",
      "         2705,   13,  260,   14,  146,   38,    0,    0,    6, 1068,    3,    0,\n",
      "          515,    0,    8,  748,  157, 3451,    1],\n",
      "        [ 272, 1197,    4,  977,  680, 1113,  739,   13,   27,   14,   27,   15,\n",
      "            2,  272,  439,    4,    5,  977,    0,    0,    2,  739,   10,   55,\n",
      "           34,    5,    0,    6,    2,   51,    1,    9,    1,    0,    4,  145,\n",
      "         1895,  931, 1271,   68,  477,    0,    0,   88,  159,    8,    5,  651,\n",
      "         3445,    7,    2,  347,    1,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0],\n",
      "        [ 203,    0,  617,    0,    3, 1761,    0,  980,  757,    8, 2508, 1111,\n",
      "           33,   96,   37, 1083,    4,  963,    2,    0,    6,    0, 1195,   24,\n",
      "            0,    2,  617, 2372,   10,    0,  303,   19,    4,  414,    0,   10,\n",
      "            0,   17,  969,    2,    0,    4, 3998,    2, 1834,   12,    9, 4632,\n",
      "            1,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0],\n",
      "        [4190, 2982, 2462,   36,  294,  126, 1101,   23,   73,    3,  670,  782,\n",
      "           13,   23, 3213,   14,  796,   20, 3937, 3960,  233,   17,    5,  549,\n",
      "          890,    6,  316,  770, 1857,    0,    0, 2443, 4190,    0, 2462,    2,\n",
      "           36,  294,  126,    0,    1,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0],\n",
      "        [ 145,  392, 1154,  175,    0,    0,    0,  276,    0,    0,    6,    2,\n",
      "           88,  159,    0,  256, 2396,   10,    5,    0,  313,  750, 3439,    0,\n",
      "          803,   90,  568,    0,    4,    2,  276,  707,    7,    5,  221,  145,\n",
      "          515,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0],\n",
      "        [  51,    1,    9,    1,  323,    3, 1085,  352, 3745,  208, 2520, 1150,\n",
      "           13,   27,   14,   27,   15,   51,    1,    9,    1, 1354,    8, 4303,\n",
      "            0,   16, 3438, 2520, 3109,  435,    5, 2313, 2354,    8,    0,    7,\n",
      "         1032,  258,   10,   65,    3, 1919,   26,    1,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0],\n",
      "        [1036,   12,    9,  816, 1813,  117,   38, 1173, 4214, 1036,   12,    9,\n",
      "          199,  125, 2519,    0,    0,   28,  682, 1173,   63, 1629,  854, 4214,\n",
      "            3,  603,   49, 4302,    2,   44,   61,  117,   44,  918,    1,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0],\n",
      "        [ 211,  699,  109,    0,    5, 4853,    0,    0,  841,  211,  699,   40,\n",
      "           47,    0, 3620,  391,    7,  366,   97,   18,    5,  109,   38,  270,\n",
      "           20, 4264,  957,    1,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([79, 53, 49, 41, 38, 44, 35, 28])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(batch[0])\n",
    "print(batch[1])\n",
    "batch[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 50\n",
    "DROPOUT = 0.5\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "EMBEDDING_DIM = 128\n",
    "BIDIRECTIONAL = True\n",
    "HIDDEN_DIM = 256\n",
    "NUM_LAYERS = 2\n",
    "OUTPUT_DIM = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VanillaRNN(vocab_size, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, NUM_LAYERS)\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, loss_function, optim, epochs):\n",
    "    losses = [] #group losses for loss visualization \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch %d / %d\" % (epoch+1, epochs))\n",
    "        print(\"-\"*10)\n",
    "        model.train()\n",
    "    \n",
    "        for i, batch_data in enumerate(train_loader):\n",
    "            \n",
    "            (y, x, x_size) = batch_data\n",
    "            print(\"Labels: {}, data: {}, x_size.cpu(): {}\".format(batch_data[0], x.shape,x_size.cpu()))\n",
    "            h_s = model.init_h() #initialize hidden state \n",
    "\n",
    "            logits = model(x, x_size.cpu())\n",
    "            loss = loss_function(logits, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss)\n",
    "\n",
    "            if(i % 10):\n",
    "              print(\"Step: {}/{}, current Epoch loss: {:.4f}\".format(i, len(train_loader), loss))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 50\n",
      "----------\n",
      "Labels: tensor([3, 2, 2, 0, 1, 0, 2, 0], device='cuda:0'), data: torch.Size([8, 60]), x_size.cpu(): tensor([60, 54, 51, 43, 40, 45, 34, 25])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aryaman.pandya/ml_accel/lib/python3.8/site-packages/torch/utils/data/datapipes/iter/combining.py:297: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PackedSequence' object has no attribute 'contiguous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(model, train_loader, torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49mcross_entropy, optimizer, NUM_EPOCHS)\n",
      "Cell \u001b[0;32mIn[63], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, loss_function, optim, epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLabels: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, data: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, x_size.cpu(): \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(batch_data[\u001b[39m0\u001b[39m], x\u001b[39m.\u001b[39mshape,x_size\u001b[39m.\u001b[39mcpu()))\n\u001b[1;32m     13\u001b[0m h_s \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39minit_h() \u001b[39m#initialize hidden state \u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m logits \u001b[39m=\u001b[39m model(x, x_size\u001b[39m.\u001b[39;49mcpu())\n\u001b[1;32m     16\u001b[0m loss \u001b[39m=\u001b[39m loss_function(logits, y)\n\u001b[1;32m     17\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/ml_accel/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[49], line 43\u001b[0m, in \u001b[0;36mVanillaRNN.forward\u001b[0;34m(self, x, x_len)\u001b[0m\n\u001b[1;32m     39\u001b[0m output, hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrnn(x_packed)  \u001b[39m# Pass the initial hidden state 'h' to the RNN\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39m# Flatten the output tensor to match the linear layer input size\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39;49mcontiguous()\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_size)\n\u001b[1;32m     45\u001b[0m \u001b[39m# Apply dropout to the concatenated hidden state\u001b[39;00m\n\u001b[1;32m     46\u001b[0m hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropoutLayer(hidden)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PackedSequence' object has no attribute 'contiguous'"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, torch.nn.functional.cross_entropy, optimizer, NUM_EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_accel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
